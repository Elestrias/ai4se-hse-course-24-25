# Лабораторная Работа №1: Классификация токсичных коментариев 
### Автор: Гильванов Руслан Маратович, MSP241


## Описание истории решения
В процессе решения данной лабораторной работе я столкнулся с множеством интересных вопросов и проблем. <br>
Разработка решения началась с реализации препроцессинга данных.

Для этой задачи было выявлено несколько методов:

Классический препроцессинг
1. Почистить датасет от незаполненых строк или строк содержащих NaN. Фактически имплеиментируется<br>
в конце пайплайна, т.к. текст может быть не пустым, но не содержать допустимых токенов.
----
Для обеспечения однородности данных. <br>
Не смотря на то что наличие схожих семплов в выборке нельзя считать полноценной утечкой данных, <br>
чрезмерное повторение коротких последовательностей токенов может помешать обобщающей способности модели. <br>
Так же роль может играть явление, которое называется Undersampling/Oversampling. В том числе потому что короткие <br> 
последовательности и ассоциированные с ними токены будут встречаться чаще, т.к. последовательности распределены <br>
логнормально (doi = {10.1098/rsos.191023}). С другой стороны длинные последовательности имеют меньше шансов на <br>
возникновение дупликатов. Следовательно, удаление дупликатов должно сгладить распределение кластеров <br>
последовательностей токенов и сделать данные однороднее.

2. Удаление дупликатов
----
Для удаления лишней информации которая "отвлекает" модель, увеличивая словарь токенов, не неся в себе полезной информации.

3. Удаление картинок зашитых как иньекции в текст
4. Удаление ссылок добавленых в текст
5. Удаление ip адресов
6. Удаление несмысловых токенов (местоимения, предлоги т.д.) - stopwords
---
Для унификации токенов в данных

8. Удаление ненужных пробелов, которые используются для сокрытия истинного смысла слов
9. Приведение к нижнему регистру 
10. Замена сокращений на полные фразы
11. Удаление пунктуации и прочих спец символов
12. Лемматизация токенов (wolves -> wolf)
---
Форматирование данных, уникальное для каждой модели

12. Токенизация
13. Векторизация

Замечу, что предложенный вариант преобразования намеренно испорченных ругательных слов<br>
с использованием словаря из исходного репозитория сильно нарушал структуру токенов, ломал<br>
слова и предложения, что в целом оказывало скорее негативный вклад в чистоту данных для модели.

Несмотря на это, в угоду требованиям задания, этот этап был оставлен в пайплайне очистки данных.

Далее началась работа над моделью. Первой проблемой стал формат данных исходивших из kFoldCrossValidation.split()

Данные без ошибок не хотели векторизировться, однако путем проб верное преобразование было вычислено.<br>
Для векторизации был взят tfidf так как он лучше векторизирует данные для этой задачи

В качесве классической модели была взята модель LogisticRegression. В отличие от так же предложенного случайного леса (RandomForest), <br>
Логистическа Регрессия является пробабалистической моделью, семантически эквивалентной простейщей Искуственной Нейронной Сети с сигмоидной<br>
функцией активации и единственным скрытым слоем. Рассчет весов в такой Нейронной Сети предстаёт в тех же функциях, состоящих из многочлена в<br>
экспоненте сигмоиды, что и в Логистической Регрессии. Выбор семантически более схожей с трансформарами семейства BERT модели обусловлен <br>
простортой их сравнения, а так же интуитивно понятным и неограниченным потенциалом для расширения модели в виде Нейронных Сетей. <br>
Случайный лес, тем не менее ограничен бустинговыми моделями, что не даёт большого потенциала для развития, потому нет смысла сравнивать его <br>
с вычислительно более совершенными трансформерами.

 
-----------
После общей настройки модели и получении первых результатов было принято решение провести тюнинг модели с использованием GridSearchCV.<br>
Его внутренне устройство предполагает использование крос-валидации, потому было решено уйти от kFoldCrossValidation в пользу более<br>
нативного инстурмента для подбора параметров Логистической Регрессии.

В результате обучения всех вариантов моделей и валидации их на 10 фолдах была выбрана модель с параметрами 

    {'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}


### Оценка confusion_matrix для LogisticRegression
При оценке модели была составлена следующая матрица ошибок

|       | false | true |
|-------|-------|------|
| false | 1919     | 77    |
| true  | 126     | 377    |

Из нее можно сделать вывод что модель хорошо обучилась определять ОТСУТСВИЕ токсичных слов в тексте.

А вот с определением НАЛИЧИЯ токсичности в тексте у модели проблемы.


После анализа датасета стало понятно, что большая часть данных смещена в пользу семплов не содержащих токсичных слов,<br>
то есть распредение внутри датасета неравномерно, из-за чего модель склонна чаще говорить, что текст не токсичен, ведь <br>
тогда, в среднем, она даст правильный ответ в большем количестве случаев.

Такое явление называются недостаточной выборкой или undersampling. Подобные вещи очень сильно влияют на модель<br>
и вырабатывают предвзятость.

Оценивая модель исключительно или приемущественно на токсичном тексте мы получили бы не самые удолетворительные результаты.<br>
Соответсвенно, использование модели, обученной на таком датасете может быть нецелесообразным в случае обратной ситуации, называемой<br>
увеличением выборки или oversampling.

Однако усиленная чистка датасета для выравнивания распределения считаю в данной работе черезмерна, так как смысл лаб. работы познакомится<br>
с интрументами и, также, потому, что бездумное удаление большего количества семплов может вызвать даже более пагубный результат. Так, например,<br>
не быо указано следует ли делать акцент на percision или recall, от чего меняется целеполагание и выводы о пользе изменений.


### Обучение моделей семейства BERT
В ходе обучения BERT моделей были рассмотрены предобученные вариации RoBERTa. В частности, обычная RoBERTa и CodeBERT являющийся, по сути, той же RoBERTa,<br>
но обученный на датасете CodeSearchNet. Обучение проходило на базе библиотеки transformers и подгрузкой предобученных моделей с платформы hugging-face.

В качестве токекнизатора использовался проприетарный RobertaTokenizer, похожий на sentencepiece вниманием к расположению слова в<br>
последовательности токенов и имплементацией BPE (Byte pair encoding). Такой мехъанизм позволяет фиксировать размер словаря, агломеративно<br>
объединяя токены. Интерфейсом обучения был класс Trainer из той же библиотеки transformers.

###  Сравнение моделей
Важно: после составления данного репорта были проведены дополнительные прогоны кода, так что цифры в pynb файлах могут слегка отличаться от представленных


#### Лучший из LogisticRegression

**Accuracy:** 0.919

**F1 Score:** 0.788 

**Precision:** 0.83

**RECALL:**  0.75

**AUC:** 0.855

**LOG_LOSS:** 2.928

--------------------------

#### ROBERTA


**Accuracy:** 0.839

**Precision:** 0.860

**Recall:** 0.839

**F1 Score:** 0.846

----

#### CODEBERT

**Accuracy:** 0.871

**Precision:** 0.890

**Recall:** 0.871

**F1 Score:** 0.877

---------
### Вывод
Предсказуемо модели семейства BERT справились с задачей лучше. Однако Логистическая Регрессия отстаёт не сильно. Несмотря на низкий recall, f1 метрика<br>
страдает не сильно. Любопытно что Логистическая Регрессия достигает более высокой точности по сравнению с BERT моделями, несмотря на заметное отставание<br>
по остальным метрикам. Это одно из проявлений так называемого Undersampling. Он в свою очередь влияет на завышенное количество True Negative значений, которые не<br>
учитываются в подсчёте таких метрик как recall, precision и f1 score, однако учитываются в accuracy. Иными словами, мы можем сделать вывод о том что при<br>
чрезмерно высокой accuracy и не таким высоким f1 score мы наблюдаем высокую specificity.

BERT модели показали себя лучше в том отношении что при совершении большего количества ошибок, они были равномернее распределены между ошибками первого и второго типов.<br>
Исходя из этого, я бы сказал что BERT модели справились значительно лучше, такая модель показала бы себя в модерации текстового контента более выгодно.<br>
Логистическая Регрессия же показала себя приемущественно в определении нетоксичного контента, потому я бы её использовал только в мультимодальной схеме для<br>
реализации более надёжеого агента фильтрации.
